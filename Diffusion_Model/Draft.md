我是不是可以这么理解。首先我们会有一团学习器parameter（当然一般是一个神经网络），我们称为P。 

 之后我们每一组放入模型的数据由以下构成： 

+ t（一般是一个整数，告诉模型现在在哪个步骤了）
+ Xt (t时刻的图像) 

 模型要做的事情就是基于t和Xt来预测t step中我们到底添加了什么高斯噪声





一开始有一个疑问

> 首先，模型P所做的事情是如何对一个图形进行去噪。而这个噪声一开始是由人通过某种规则添加的对吧？本质我们是让模型学习人添加噪声的规律？这真的有意义吗，因为我们不需要用模型去学习一个我们已知的东西



但是实际上我们学习的是低信图形与真实图像的差值（某种程度上是一种有效学习真实图像分布的有效训练范式）





或者说模型P是预测t时刻的噪声图，它是一个size等于原图，同时也存在RBG通道的图。（所以本质diffusion提出了一个通过学习噪声图进而来学习真实世界（给定）图像分布的训练范式



![U-Net 的图像结果](https://th.bing.com/th/id/OIP.lvXoKMHoPJMKpKK7keZMEAHaE7?w=253&h=180&c=7&r=0&o=7&cb=12&dpr=2&pid=1.7&rm=3)